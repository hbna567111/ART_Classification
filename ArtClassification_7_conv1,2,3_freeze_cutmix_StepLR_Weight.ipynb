{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "708d6685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_acolman-1...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>acolman-1-1955</td>\n",
       "      <td>bebbeb018a7d80a8</td>\n",
       "      <td>1922</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_chicago-6...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>chicago-6-1961</td>\n",
       "      <td>d7d0781be51fc00e</td>\n",
       "      <td>1382</td>\n",
       "      <td>1746</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_glouceste...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>gloucester-16a-1944</td>\n",
       "      <td>9f846e5a6c639325</td>\n",
       "      <td>1382</td>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_jerome-ar...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>jerome-arizona-1949</td>\n",
       "      <td>a5d691f85ac5e4d0</td>\n",
       "      <td>1382</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_kentucky-...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>kentucky-4-1951</td>\n",
       "      <td>880df359e6b11db1</td>\n",
       "      <td>1382</td>\n",
       "      <td>1625</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/aaron-siskind_acolman-1...  aaron siskind   \n",
       "1  Abstract_Expressionism/aaron-siskind_chicago-6...  aaron siskind   \n",
       "2  Abstract_Expressionism/aaron-siskind_glouceste...  aaron siskind   \n",
       "3  Abstract_Expressionism/aaron-siskind_jerome-ar...  aaron siskind   \n",
       "4  Abstract_Expressionism/aaron-siskind_kentucky-...  aaron siskind   \n",
       "\n",
       "                        genre          description             phash  width  \\\n",
       "0  ['Abstract Expressionism']       acolman-1-1955  bebbeb018a7d80a8   1922   \n",
       "1  ['Abstract Expressionism']       chicago-6-1961  d7d0781be51fc00e   1382   \n",
       "2  ['Abstract Expressionism']  gloucester-16a-1944  9f846e5a6c639325   1382   \n",
       "3  ['Abstract Expressionism']  jerome-arizona-1949  a5d691f85ac5e4d0   1382   \n",
       "4  ['Abstract Expressionism']      kentucky-4-1951  880df359e6b11db1   1382   \n",
       "\n",
       "   height  genre_count subset  \n",
       "0    1382            1  train  \n",
       "1    1746            1  train  \n",
       "2    1857            1  train  \n",
       "3    1849            1  train  \n",
       "4    1625            1  train  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_classes = pd.read_csv('./archive/classes.csv')\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99cfbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n"
     ]
    }
   ],
   "source": [
    "print(len(df_classes.groupby([\"artist\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bb60f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subset</th>\n",
       "      <th>artist</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>uncertain artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>378</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>363</td>\n",
       "      <td>1453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>pierre auguste renoir</td>\n",
       "      <td>280</td>\n",
       "      <td>1117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>claude monet</td>\n",
       "      <td>267</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>pyotr konchalovsky</td>\n",
       "      <td>185</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>camille pissarro</td>\n",
       "      <td>177</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>albrecht durer</td>\n",
       "      <td>166</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>john singer sargent</td>\n",
       "      <td>157</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>rembrandt</td>\n",
       "      <td>155</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>marc chagall</td>\n",
       "      <td>153</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>153</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>gustave dore</td>\n",
       "      <td>151</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>boris kustodiev</td>\n",
       "      <td>127</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>edgar degas</td>\n",
       "      <td>122</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>paul cezanne</td>\n",
       "      <td>116</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ivan aivazovsky</td>\n",
       "      <td>116</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>martiros saryan</td>\n",
       "      <td>115</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>eugene boudin</td>\n",
       "      <td>111</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>childe hassam</td>\n",
       "      <td>110</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ilya repin</td>\n",
       "      <td>108</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>104</td>\n",
       "      <td>416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>raphael kirchner</td>\n",
       "      <td>103</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>henri matisse</td>\n",
       "      <td>98</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>salvador dali</td>\n",
       "      <td>96</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>camille corot</td>\n",
       "      <td>96</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subset                 artist  test  train  uncertain artist\n",
       "1074         vincent van gogh   378   1510                 0\n",
       "809          nicholas roerich   363   1453                 0\n",
       "898     pierre auguste renoir   280   1117                 2\n",
       "190              claude monet   267   1067                 0\n",
       "917        pyotr konchalovsky   185    739                 0\n",
       "158          camille pissarro   177    707                 0\n",
       "34             albrecht durer   166    662                 0\n",
       "599       john singer sargent   157    625                 1\n",
       "932                 rembrandt   155    621                 0\n",
       "719              marc chagall   153    612                 0\n",
       "846             pablo picasso   153    610                 0\n",
       "420              gustave dore   151    602                 0\n",
       "148           boris kustodiev   127    506                 0\n",
       "252               edgar degas   122    487                 2\n",
       "859              paul cezanne   116    463                 0\n",
       "495           ivan aivazovsky   116    461                 0\n",
       "749           martiros saryan   115    461                 0\n",
       "289             eugene boudin   111    444                 0\n",
       "180             childe hassam   110    437                 0\n",
       "476                ilya repin   108    431                 0\n",
       "504             ivan shishkin   104    416                 0\n",
       "929          raphael kirchner   103    413                 0\n",
       "448             henri matisse    98    393                 0\n",
       "978             salvador dali    96    385                 0\n",
       "157             camille corot    96    381                 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:10722, valid:5281, test:4007\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_TOP = 25\n",
    "\n",
    "df = df_classes.groupby([\"subset\",\"artist\"]).size().reset_index()\n",
    "df.columns = [\"subset\", \"artist\", \"size\"]\n",
    "df = df.pivot(index=\"artist\",columns=\"subset\", values=\"size\")\n",
    "df = df.reset_index()\n",
    "df = df.fillna(0).sort_values(by=\"train\", ascending=False)\n",
    "df[\"train\"] = df[\"train\"].astype(np.int16)\n",
    "df[\"test\"] = df[\"test\"].astype(np.int16)\n",
    "df[\"uncertain artist\"] = df[\"uncertain artist\"].astype(np.int16)\n",
    "\n",
    "df=df.sort_values(by=\"train\", ascending=False)\n",
    "\n",
    "top_artists = df[\"artist\"].values[:N_TOP]\n",
    "display(df.head(N_TOP))\n",
    "\n",
    "df_all = df_classes[df_classes[\"artist\"].isin(top_artists)].reset_index(drop = True)\n",
    "le = LabelEncoder()\n",
    "df_all[\"artist_class\"] = le.fit_transform(df_all[\"artist\"].values)\n",
    "class_names = le.classes_\n",
    "\n",
    "    \n",
    "    \n",
    "df_train = df_all.query(\"subset == 'train'\").reset_index(drop = True)\n",
    "df_test = df_all.query(\"subset == 'test'\").reset_index(drop = True)\n",
    "\n",
    "\n",
    "df_train, df_valid, y_train, y_valid =  train_test_split(df_train, df_train[\"artist\"], \n",
    "                                                                   test_size=0.33, random_state=42, \n",
    "                                                                   stratify=df_train[\"artist\"])\n",
    "\n",
    "\n",
    "print(f\"train:{df_train.shape[0]}, valid:{df_valid.shape[0]}, test:{df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "471c43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index().reset_index().rename({\"index\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f56c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(labels=\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be19de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"level_0\":\"index\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91354dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Naive_Art_Primitivism/pablo-picasso_jug-with-h...</td>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>['Naive Art Primitivism']</td>\n",
       "      <td>jug-with-handle-1954</td>\n",
       "      <td>c8263591cb59b567</td>\n",
       "      <td>1382</td>\n",
       "      <td>2132</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Impressionism/henri-matisse_blue-pot-and-lemon...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Impressionism']</td>\n",
       "      <td>blue-pot-and-lemon-1897</td>\n",
       "      <td>8c8ca5955e6a639b</td>\n",
       "      <td>1668</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Realism/nicholas-roerich_the-kremlin-tower-of-...</td>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>the-kremlin-tower-of-novgorod-1903</td>\n",
       "      <td>f6d6b6b6b6048425</td>\n",
       "      <td>1382</td>\n",
       "      <td>1539</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Realism/ivan-shishkin_polesye.jpg</td>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>polesye</td>\n",
       "      <td>83ed70178ee36e18</td>\n",
       "      <td>2314</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Post_Impressionism/vincent-van-gogh_still-life...</td>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>still-life-with-apples-1887</td>\n",
       "      <td>87e4b097c4e80fd5</td>\n",
       "      <td>1935</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           filename            artist  \\\n",
       "0      0  Naive_Art_Primitivism/pablo-picasso_jug-with-h...     pablo picasso   \n",
       "1      1  Impressionism/henri-matisse_blue-pot-and-lemon...     henri matisse   \n",
       "2      2  Realism/nicholas-roerich_the-kremlin-tower-of-...  nicholas roerich   \n",
       "3      3                  Realism/ivan-shishkin_polesye.jpg     ivan shishkin   \n",
       "4      4  Post_Impressionism/vincent-van-gogh_still-life...  vincent van gogh   \n",
       "\n",
       "                       genre                         description  \\\n",
       "0  ['Naive Art Primitivism']                jug-with-handle-1954   \n",
       "1          ['Impressionism']             blue-pot-and-lemon-1897   \n",
       "2                ['Realism']  the-kremlin-tower-of-novgorod-1903   \n",
       "3                ['Realism']                             polesye   \n",
       "4     ['Post Impressionism']         still-life-with-apples-1887   \n",
       "\n",
       "              phash  width  height  genre_count subset  artist_class  \n",
       "0  c8263591cb59b567   1382    2132            1  train            17  \n",
       "1  8c8ca5955e6a639b   1668    1382            1  train             9  \n",
       "2  f6d6b6b6b6048425   1382    1539            1  train            16  \n",
       "3  83ed70178ee36e18   2314    1382            1  train            12  \n",
       "4  87e4b097c4e80fd5   1935    1382            1  train            24  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8b71a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude-1952</td>\n",
       "      <td>afbcd133d0ccc069</td>\n",
       "      <td>1382</td>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude</td>\n",
       "      <td>ff58d824d109cc6e</td>\n",
       "      <td>1382</td>\n",
       "      <td>2145</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs-1</td>\n",
       "      <td>b2cf336117ca8713</td>\n",
       "      <td>2092</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs.jpg</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs</td>\n",
       "      <td>bff3c8b6c0c9c08c</td>\n",
       "      <td>2082</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_la-gerbe-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>la-gerbe-1953</td>\n",
       "      <td>acbccdc290b3db05</td>\n",
       "      <td>1675</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "1  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "2  Abstract_Expressionism/henri-matisse_cut-outs-...  henri matisse   \n",
       "3  Abstract_Expressionism/henri-matisse_cut-outs.jpg  henri matisse   \n",
       "4  Abstract_Expressionism/henri-matisse_la-gerbe-...  henri matisse   \n",
       "\n",
       "                        genre     description             phash  width  \\\n",
       "0  ['Abstract Expressionism']  blue-nude-1952  afbcd133d0ccc069   1382   \n",
       "1  ['Abstract Expressionism']       blue-nude  ff58d824d109cc6e   1382   \n",
       "2  ['Abstract Expressionism']      cut-outs-1  b2cf336117ca8713   2092   \n",
       "3  ['Abstract Expressionism']        cut-outs  bff3c8b6c0c9c08c   2082   \n",
       "4  ['Abstract Expressionism']   la-gerbe-1953  acbccdc290b3db05   1675   \n",
       "\n",
       "   height  genre_count subset  artist_class  \n",
       "0    1769            1   test             9  \n",
       "1    2145            1   test             9  \n",
       "2    1382            1   test             9  \n",
       "3    1382            1   test             9  \n",
       "4    1382            1   test             9  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57259e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam): # size : [B, C, W, H]\n",
    "    W = size[2] # 이미지의 width\n",
    "    H = size[3] # 이미지의 height\n",
    "    cut_rat = np.sqrt(1. - lam)  # 패치 크기의 비율 정하기\n",
    "    cut_w = np.int32(W * cut_rat)  # 패치의 너비\n",
    "    cut_h = np.int32(H * cut_rat)  # 패치의 높이\n",
    "\n",
    "    # uniform\n",
    "    # 기존 이미지의 크기에서 랜덤하게 값을 가져옵니다.(중간 좌표 추출)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 패치 부분에 대한 좌표값을 추출합니다.\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f51a4f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    ds_path = \"./archive/\"\n",
    "    filenames = [ f\"{ds_path}/{filename}\" for filename in  df[\"filename\"].values]\n",
    "    labels = [artist for artist in df[\"artist_class\"]]\n",
    "    #ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    #return ds\n",
    "    return filenames,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdb37ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_data(df_train)\n",
    "val_img_paths, val_labels = get_data(df_valid)\n",
    "test_img_paths, test_labels = get_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a4799df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Data Imbalance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0e3995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_class\n",
       "0      444\n",
       "1      339\n",
       "2      255\n",
       "3      474\n",
       "4      293\n",
       "5      715\n",
       "6      326\n",
       "7      297\n",
       "8      403\n",
       "9      263\n",
       "10     289\n",
       "11     309\n",
       "12     279\n",
       "13     419\n",
       "14     410\n",
       "15     309\n",
       "16     973\n",
       "17     409\n",
       "18     310\n",
       "19     748\n",
       "20     495\n",
       "21     277\n",
       "22     416\n",
       "23     258\n",
       "24    1012\n",
       "Name: artist_class, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('artist_class')['artist_class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = list(df_train.groupby('artist_class')['artist_class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "04cb0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[444,\n",
       " 339,\n",
       " 255,\n",
       " 474,\n",
       " 293,\n",
       " 715,\n",
       " 326,\n",
       " 297,\n",
       " 403,\n",
       " 263,\n",
       " 289,\n",
       " 309,\n",
       " 279,\n",
       " 419,\n",
       " 410,\n",
       " 309,\n",
       " 973,\n",
       " 409,\n",
       " 310,\n",
       " 748,\n",
       " 495,\n",
       " 277,\n",
       " 416,\n",
       " 258,\n",
       " 1012]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "016702aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "albrecht durer            444\n",
       "boris kustodiev           339\n",
       "camille corot             255\n",
       "camille pissarro          474\n",
       "childe hassam             293\n",
       "claude monet              715\n",
       "edgar degas               326\n",
       "eugene boudin             297\n",
       "gustave dore              403\n",
       "henri matisse             263\n",
       "ilya repin                289\n",
       "ivan aivazovsky           309\n",
       "ivan shishkin             279\n",
       "john singer sargent       419\n",
       "marc chagall              410\n",
       "martiros saryan           309\n",
       "nicholas roerich          973\n",
       "pablo picasso             409\n",
       "paul cezanne              310\n",
       "pierre auguste renoir     748\n",
       "pyotr konchalovsky        495\n",
       "raphael kirchner          277\n",
       "rembrandt                 416\n",
       "salvador dali             258\n",
       "vincent van gogh         1012\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"artist\")['artist'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15e86729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 22,\n",
       " 19,\n",
       " 24,\n",
       " 13,\n",
       " 24,\n",
       " 22,\n",
       " 8,\n",
       " 5,\n",
       " 17,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 0,\n",
       " 16,\n",
       " 23,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 2,\n",
       " 18,\n",
       " 12,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 11,\n",
       " 17,\n",
       " 21,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 6,\n",
       " 17,\n",
       " 3,\n",
       " 1,\n",
       " 14,\n",
       " 24,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 14,\n",
       " 10,\n",
       " 8,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 17,\n",
       " 19,\n",
       " 10,\n",
       " 24,\n",
       " 20,\n",
       " 0,\n",
       " 0,\n",
       " 20,\n",
       " 9,\n",
       " 24,\n",
       " 8,\n",
       " 12,\n",
       " 14,\n",
       " 5,\n",
       " 24,\n",
       " 3,\n",
       " 17,\n",
       " 13,\n",
       " 24,\n",
       " 7,\n",
       " 5,\n",
       " 13,\n",
       " 20,\n",
       " 0,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 24,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 8,\n",
       " 12,\n",
       " 19,\n",
       " 9,\n",
       " 20,\n",
       " 0,\n",
       " 17,\n",
       " 22,\n",
       " 2,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 22,\n",
       " 9,\n",
       " 19,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 23,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 21,\n",
       " 22,\n",
       " 11,\n",
       " 23,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 19,\n",
       " 15,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 14,\n",
       " 20,\n",
       " 2,\n",
       " 21,\n",
       " 12,\n",
       " 21,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 18,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 13,\n",
       " 24,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 24,\n",
       " 4,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 6,\n",
       " 21,\n",
       " 2,\n",
       " 19,\n",
       " 22,\n",
       " 24,\n",
       " 7,\n",
       " 10,\n",
       " 24,\n",
       " 3,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 11,\n",
       " 20,\n",
       " 5,\n",
       " 19,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 14,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 16,\n",
       " 24,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 0,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 22,\n",
       " 14,\n",
       " 0,\n",
       " 11,\n",
       " 19,\n",
       " 24,\n",
       " 14,\n",
       " 10,\n",
       " 21,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 1,\n",
       " 24,\n",
       " 0,\n",
       " 9,\n",
       " 19,\n",
       " 19,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 24,\n",
       " 10,\n",
       " 4,\n",
       " 18,\n",
       " 16,\n",
       " 8,\n",
       " 22,\n",
       " 15,\n",
       " 3,\n",
       " 18,\n",
       " 14,\n",
       " 24,\n",
       " 5,\n",
       " 14,\n",
       " 23,\n",
       " 19,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 0,\n",
       " 16,\n",
       " 20,\n",
       " 3,\n",
       " 17,\n",
       " 23,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 6,\n",
       " 17,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 24,\n",
       " 16,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 15,\n",
       " 11,\n",
       " 24,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 16,\n",
       " 4,\n",
       " 24,\n",
       " 20,\n",
       " 10,\n",
       " 24,\n",
       " 21,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 17,\n",
       " 24,\n",
       " 24,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 20,\n",
       " 13,\n",
       " 11,\n",
       " 16,\n",
       " 18,\n",
       " 14,\n",
       " 8,\n",
       " 23,\n",
       " 24,\n",
       " 5,\n",
       " 13,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 17,\n",
       " 13,\n",
       " 22,\n",
       " 16,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 17,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 21,\n",
       " 4,\n",
       " 5,\n",
       " 21,\n",
       " 20,\n",
       " 3,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 22,\n",
       " 18,\n",
       " 24,\n",
       " 23,\n",
       " 16,\n",
       " 23,\n",
       " 3,\n",
       " 18,\n",
       " 22,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 21,\n",
       " 9,\n",
       " 24,\n",
       " 3,\n",
       " 1,\n",
       " 18,\n",
       " 10,\n",
       " 15,\n",
       " 3,\n",
       " 13,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 7,\n",
       " 20,\n",
       " 6,\n",
       " 22,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 22,\n",
       " 12,\n",
       " 5,\n",
       " 21,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 16,\n",
       " 17,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 19,\n",
       " 14,\n",
       " 20,\n",
       " 23,\n",
       " 13,\n",
       " 11,\n",
       " 1,\n",
       " 15,\n",
       " 13,\n",
       " 24,\n",
       " 13,\n",
       " 9,\n",
       " 4,\n",
       " 19,\n",
       " 11,\n",
       " 24,\n",
       " 11,\n",
       " 8,\n",
       " 2,\n",
       " 24,\n",
       " 7,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 13,\n",
       " 23,\n",
       " 5,\n",
       " 15,\n",
       " 11,\n",
       " 16,\n",
       " 23,\n",
       " 11,\n",
       " 21,\n",
       " 16,\n",
       " 20,\n",
       " 2,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 9,\n",
       " 12,\n",
       " 18,\n",
       " 8,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 20,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 23,\n",
       " 22,\n",
       " 2,\n",
       " 16,\n",
       " 5,\n",
       " 18,\n",
       " 15,\n",
       " 19,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 23,\n",
       " 20,\n",
       " 1,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 18,\n",
       " 0,\n",
       " 16,\n",
       " 12,\n",
       " 11,\n",
       " 3,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 22,\n",
       " 24,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 22,\n",
       " 6,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 3,\n",
       " 15,\n",
       " 4,\n",
       " 20,\n",
       " 3,\n",
       " 23,\n",
       " 6,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 12,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 21,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 15,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 5,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 23,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 3,\n",
       " 22,\n",
       " 4,\n",
       " 22,\n",
       " 22,\n",
       " 0,\n",
       " 7,\n",
       " 22,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 16,\n",
       " 24,\n",
       " 17,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 17,\n",
       " 1,\n",
       " 17,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 23,\n",
       " 5,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 23,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 13,\n",
       " 20,\n",
       " 17,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 20,\n",
       " 0,\n",
       " 16,\n",
       " 14,\n",
       " 1,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 18,\n",
       " 8,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 5,\n",
       " 24,\n",
       " 18,\n",
       " 20,\n",
       " 3,\n",
       " 10,\n",
       " 17,\n",
       " 24,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 24,\n",
       " 16,\n",
       " 22,\n",
       " 4,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 22,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 5,\n",
       " 19,\n",
       " 7,\n",
       " 7,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 23,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 17,\n",
       " 20,\n",
       " 12,\n",
       " 24,\n",
       " 16,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 20,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 5,\n",
       " 21,\n",
       " 17,\n",
       " 5,\n",
       " 11,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 4,\n",
       " 24,\n",
       " 16,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 24,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 11,\n",
       " 6,\n",
       " 20,\n",
       " 11,\n",
       " 24,\n",
       " 1,\n",
       " 16,\n",
       " 5,\n",
       " 19,\n",
       " 5,\n",
       " 17,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 12,\n",
       " 5,\n",
       " 13,\n",
       " 6,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 20,\n",
       " 16,\n",
       " 17,\n",
       " 3,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 14,\n",
       " 5,\n",
       " 14,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 5,\n",
       " 16,\n",
       " 10,\n",
       " 24,\n",
       " 0,\n",
       " 21,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 21,\n",
       " 22,\n",
       " 16,\n",
       " 1,\n",
       " 23,\n",
       " 18,\n",
       " 11,\n",
       " 24,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 3,\n",
       " 15,\n",
       " 7,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 18,\n",
       " 19,\n",
       " 3,\n",
       " 17,\n",
       " 6,\n",
       " 12,\n",
       " 19,\n",
       " 15,\n",
       " 20,\n",
       " 11,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 20,\n",
       " 14,\n",
       " 9,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 16,\n",
       " 24,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 24,\n",
       " 1,\n",
       " 3,\n",
       " 20,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 24,\n",
       " 13,\n",
       " 12,\n",
       " 4,\n",
       " 14,\n",
       " 6,\n",
       " 24,\n",
       " 23,\n",
       " 14,\n",
       " 14,\n",
       " 17,\n",
       " 24,\n",
       " 20,\n",
       " 2,\n",
       " 24,\n",
       " 5,\n",
       " 24,\n",
       " 14,\n",
       " 16,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 22,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 20,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 21,\n",
       " 16,\n",
       " 10,\n",
       " 11,\n",
       " 5,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 2,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 15,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 17,\n",
       " 7,\n",
       " 19,\n",
       " 14,\n",
       " 16,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 14,\n",
       " 7,\n",
       " 22,\n",
       " 6,\n",
       " 18,\n",
       " 11,\n",
       " 20,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 14,\n",
       " 17,\n",
       " 13,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 22,\n",
       " 22,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 24,\n",
       " 3,\n",
       " 23,\n",
       " 17,\n",
       " 24,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "858812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "    labels = np.array(labels) \n",
    "    weight_arr = np.zeros_like(labels) \n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    for cls in range(nclasses):\n",
    "        weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr)\n",
    "        # 각 클래스의의 인덱스를 산출하여 해당 클래스 개수의 역수를 확률로 할당한다.\n",
    "        # 이를 통해 각 클래스의 전체 가중치를 동일하게 한다.\n",
    " \n",
    "    return weight_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "74eabd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0024, 0.0038, 0.0010,  ..., 0.0010, 0.0031, 0.0036], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w = make_weights(train_labels,25)\n",
    "w= torch.FloatTensor(w).to(\"cuda:0\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f46a32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = np.array(image)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc313479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "764bcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.VerticalFlip(p=0.5),\n",
    "                            A.ShiftScaleRotate(p=0.5),\n",
    "                            A.OneOf([\n",
    "                                A.CLAHE(clip_limit=2),\n",
    "                                A.RandomBrightnessContrast(),\n",
    "                            ], p=0.3),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0ce6c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_img_paths, val_labels, val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc60df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=False).to(\"cuda:0\")\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ef264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bd7e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e5cbeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\jiseon\\anaconda3\\envs\\test\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "842d07f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 25]          51,225\n",
      "================================================================\n",
      "Total params: 23,559,257\n",
      "Trainable params: 23,559,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.87\n",
      "Estimated Total Size (MB): 377.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary\n",
    "\n",
    "summary(resnet.to(\"cuda:0\"), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a364f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "fc.weight torch.Size([25, 2048])\n",
      "fc.bias torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    print(name,param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8a275a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "  if 'layer1' in name :\n",
    "    print(name)\n",
    "  elif 'layer2' in name:\n",
    "    print(name)\n",
    "  elif name in ['conv1.weight', 'bn1.weight', 'bn1.bias']:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dee5cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "  if 'layer1' in name :\n",
    "    param.requires_grad = False\n",
    "  elif 'layer2' in name:\n",
    "    param.requires_grad = False\n",
    "  elif name in ['conv1.weight', 'bn1.weight', 'bn1.bias']:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "333f96be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 25]          51,225\n",
      "================================================================\n",
      "Total params: 23,559,257\n",
      "Trainable params: 22,114,329\n",
      "Non-trainable params: 1,444,928\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.87\n",
      "Estimated Total Size (MB): 377.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "11610912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_path = './checkpoint/best_model_weight.pt'\n",
    "weights = torch.load(state_dict_path)\n",
    "resnet.load_state_dict(weights['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11b6de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ins = class_count    # 실제 클래스 수 \n",
    " \n",
    "weights = [1 - (x/sum(num_ins)) for x in num_ins]\n",
    "class_weights = torch.FloatTensor(weights).to(\"cuda:0\")\n",
    " \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54571f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imbalance 문제 해결 위해 CrossEntropyLoss에 Weight 적용\n",
    "# criterion = nn.CrossEntropyLoss(weight=w)\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# 10 에폭마다 0.5씩 학습률 감소\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93734263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir):\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    check_point = {\n",
    "        'net2' : model.state_dict()\n",
    "    }\n",
    "    torch.save(check_point, saved_dir+'/best_model6_weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "23be2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "def eval_model(model_ft, data_loader, device):\n",
    "  model_ft.eval()\n",
    "\n",
    "  best_acc = 0.0\n",
    "    \n",
    "  ys = []\n",
    "  ypreds = []\n",
    "  for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      _, y_pred = model_ft(x).max(1)\n",
    "    ys.append(y)\n",
    "    ypreds.append(y_pred)\n",
    "\n",
    "  ys = torch.cat(ys)\n",
    "  ypreds = torch.cat(ypreds)\n",
    "\n",
    "  acc = ((ys == ypreds).float().sum() / len(ys)) * 100\n",
    "\n",
    "  if best_acc < acc:\n",
    "        save_model(model_ft, './checkpoint')\n",
    "        print('Succeed save the model')\n",
    "        best_acc=acc\n",
    "        \n",
    "  \n",
    "  return acc.item()\n",
    "\n",
    "\n",
    "def train_model(model_ft,train_loader, val_loader, only_fc,\n",
    "                optimizer_cls,\n",
    "                loss_fn, scheduler,\n",
    "                n_iter=10, device='cpu'):\n",
    "  train_losses = []\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "\n",
    "  if only_fc:\n",
    "    optimizer = optimizer_cls\n",
    "  \n",
    "  else:\n",
    "    optimizer = optimizer_cls(model_ft.parameters())\n",
    "\n",
    "  for epoch in range(n_iter):\n",
    "    running_loss = 0.0\n",
    "    model_ft.train()\n",
    "    n = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i, (xx, yy) in tqdm(enumerate(train_loader), total= len(train_loader)):\n",
    "      yy = torch.from_numpy(np.asarray(yy))\n",
    "      xx = xx.to(device)\n",
    "      yy = yy.to(device)\n",
    "      optimizer.zero_grad()\n",
    "        # cutmix\n",
    "      if np.random.random()>0.5:\n",
    "        X, y = xx,yy\n",
    "        lam = np.random.beta(1.0, 1.0)\n",
    "        rand_index = torch.randperm(X.size()[0]).to(device)\n",
    "        target_a = y\n",
    "        target_b = y[rand_index]            \n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(X.size(), lam)\n",
    "        X[:, :, bbx1:bbx2, bby1:bby2] = X[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (X.size()[-1] * X.size()[-2]))\n",
    "        h = model_ft(X)\n",
    "        loss = loss_fn(h, target_a) * lam + loss_fn(h, target_b) * (1. - lam)\n",
    "      else:\n",
    "        h = model_ft(xx)\n",
    "        loss = loss_fn(h,yy)\n",
    "        \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      n += len(xx)\n",
    "      _,y_pred = h.max(1)\n",
    "      n_acc += (yy == y_pred).float().sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print(\"lr: \", optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    train_losses.append(running_loss/i)\n",
    "    \n",
    "    train_acc.append(n_acc / n)\n",
    "\n",
    "    val_acc.append(eval_model(model_ft, val_loader, device))\n",
    "\n",
    "    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "41740817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da96f4c06294387bbda58f06a5b56c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "0 1.8140688811182442 0.5078358208955224 67.2537841796875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405e3452d0e44f2a9adcb745ce013ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "1 1.6813841382840646 0.5503731343283582 68.20075225830078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f2f9de96ae4cbdbf358c2b3382b7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "2 1.6861325839175236 0.5467350746268657 70.30303192138672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ac4db9ea4f4ef1b06581f023cfebe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "3 1.6367410588424836 0.5580223880597015 71.09848022460938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fa5c268cec43468e50366b92a8fb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "4 1.5831765461662959 0.5835820895522388 72.08332824707031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0bc0667dc748448870026ab9f43bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "5 1.5689276474206437 0.5871268656716417 73.18181610107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2d314a875c4effb2dd74cf0b139524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "6 1.51552967613588 0.5948694029850746 73.57954406738281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8af85a8a3f542fca5ec87a7a25eb3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "7 1.501951625573439 0.5895522388059702 74.03408813476562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee204e4f3921440ea2bf25fee6635dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "8 1.4146410963193183 0.6192164179104478 74.64015197753906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91090d19ae8f4035b05ef7ca39a5d4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "9 1.4709407929971436 0.6182835820895523 75.3787841796875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df551dbb48a44f6b2c754551a52e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5e-05\n",
      "Succeed save the model\n",
      "10 1.4351901362562394 0.6253731343283582 75.70075225830078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecf2d2547d24bd0ad7a31e6783c005e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "11 1.4355089587391938 0.6226679104477612 75.13257598876953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0da7e7804d4e0490b4fed67d4768ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "12 1.4127121217136782 0.6323694029850746 75.1515121459961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b06294f92014d29847fb4d7cb5096e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "13 1.3555915375283303 0.6403917910447762 76.32575988769531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef3936850d149d3bfff6edbf81e047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "14 1.3967152657084758 0.633955223880597 75.54924011230469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca634f2a55f496c981fad61fac59606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "15 1.3908498416388873 0.6413246268656716 75.49242401123047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06c41532e144f45bfca2bbfe768543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "16 1.3716290931931525 0.6397388059701492 76.57196807861328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25762555f2954641841c3aabb1ca239a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "17 1.366143426263457 0.6438432835820895 76.11741638183594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5778e2c6516492aafd22b552f5a7006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "18 1.3707907857158972 0.6392723880597015 76.30681610107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cd97b106044b83aa08ce738e930f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "19 1.324555725037428 0.6543843283582089 75.54924011230469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c665159ee444299a006853ed867cd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.5e-05\n",
      "Succeed save the model\n",
      "20 1.369476087112954 0.6371268656716418 77.08332824707031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b9456d37dd4e06895dbb0a5f433c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "21 1.319967158974019 0.6549440298507463 76.91287231445312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc526d40fa847faaea80ab0824441c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "22 1.3425368808978342 0.6434701492537314 77.23484802246094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815ce03d70974d05a03be1960bb4d099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "23 1.347254924865938 0.6550373134328358 77.34848022460938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cbb50903d04678abac3d8f71f0cea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "24 1.3296808697762155 0.6500932835820895 77.91666412353516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9befa6958cf641749f9b78f6a31091d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "25 1.2949544234571613 0.6613805970149254 77.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72fd8644b65467e91234a3cc5fc044c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "26 1.3656014283319937 0.6472014925373134 77.2727279663086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8ba5b3d6d54b6b809d2ee9197bc4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "27 1.327034414594127 0.6454291044776119 77.34848022460938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bf0c7cc1354259ac60a281d490d64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "28 1.2990022850277179 0.6492537313432836 77.04545593261719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2ccc5ec2aa48d8a5782a1de5d0fa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "29 1.2850639541231106 0.6615671641791044 77.44317626953125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7d54e421ce45528e6f4e3eb62d68cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.25e-05\n",
      "Succeed save the model\n",
      "30 1.3447604176709471 0.6463619402985075 77.68939208984375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a60afaa5ee44ec8a60aadecfa9f441f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "31 1.3269369790194103 0.653544776119403 76.8560562133789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546aa17132a74ffab24f042f99aab11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "32 1.330564817505567 0.6585820895522388 77.04545593261719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d4d9f968341938b8cc853e5064c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "33 1.3089017241703198 0.664179104477612 77.84090423583984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9a56936f2040f78a615d42501703ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "34 1.2584780500519614 0.6722014925373134 77.51893615722656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9d7dd36d9740c3beeabd3cea5dbd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "35 1.2872444812447856 0.6670708955223881 77.2537841796875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73047d32d7214cfca17723a155000ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "36 1.2722276011300906 0.6646455223880597 77.67045593261719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f1433674194c079aa30aa3ee529d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "37 1.3101995848174943 0.6555970149253731 78.40908813476562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066adac59767462c9aa57a26375cbffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "38 1.3006765852906423 0.6642723880597015 78.61742401123047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e724ef11964238a4de445c427c2d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "39 1.269664092315152 0.6763059701492538 78.20075988769531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78dc233459648239cd2869a09a093a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.25e-06\n",
      "Succeed save the model\n",
      "40 1.2753019505507566 0.6705223880597015 77.4810562133789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e699ad95b32141edbca52bd4cd70f611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "41 1.287744935006126 0.6669776119402985 77.8977279663086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c44383afeb549f98e9327f6339c185d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "42 1.2893851152850908 0.6643656716417911 78.18181610107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda41203e2fe42b0a66305a2a019f8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "43 1.2953062685393075 0.6606343283582089 77.7272720336914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75c6d4ade514512bce1c4440e5b5b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "44 1.2631405904243167 0.6713619402985075 78.48484802246094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4058d7239a9c478eb2674a253aa964a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "45 1.2819990561592918 0.6625 78.61742401123047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36e219fa07b460898faf9f409b536b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "46 1.2880308873984845 0.6693097014925373 78.42803192138672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e945067b76f74de8aa03add05e5b0bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "47 1.279300459052237 0.6603544776119403 78.37120819091797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00205c009d6040d19c12e21aa68991cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "48 1.2742117167811045 0.6727611940298508 78.42803192138672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be7a2b423874bf1b24095ed2003350e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed save the model\n",
      "49 1.2529455283921218 0.6817164179104478 77.34848022460938\n"
     ]
    }
   ],
   "source": [
    "resnet.to(\"cuda:0\")\n",
    "\n",
    "train_model(resnet, train_loader, val_loader, only_fc = True, optimizer_cls=optimizer_ft,\n",
    "            loss_fn = criterion, scheduler = scheduler, n_iter=50, device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
